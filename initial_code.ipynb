{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NtoBmuI8tTn",
        "outputId": "4beaf12a-1300-4ec8-a6d8-bef0efdcf04e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Fetched 50 items for chicken (Page 1)\n",
            "✅ Fetched 50 items for chicken (Page 2)\n",
            "✅ Fetched 50 items for chicken (Page 3)\n",
            "✅ Fetched 50 items for chicken (Page 4)\n",
            "✅ Fetched 50 items for chicken (Page 5)\n",
            "✅ Fetched 50 items for beef (Page 1)\n",
            "✅ Fetched 50 items for beef (Page 2)\n",
            "✅ Fetched 50 items for beef (Page 3)\n",
            "✅ Fetched 50 items for beef (Page 4)\n",
            "✅ Fetched 50 items for beef (Page 5)\n",
            "✅ Fetched 50 items for pork (Page 1)\n",
            "✅ Fetched 50 items for pork (Page 2)\n",
            "✅ Fetched 50 items for pork (Page 3)\n",
            "✅ Fetched 50 items for pork (Page 4)\n",
            "✅ Fetched 50 items for pork (Page 5)\n",
            "✅ Fetched 50 items for fish (Page 1)\n",
            "✅ Fetched 50 items for fish (Page 2)\n",
            "✅ Fetched 50 items for fish (Page 3)\n",
            "❌ Error fetching data for fish: 'value'\n",
            "✅ Fetched 50 items for rice (Page 1)\n",
            "✅ Fetched 50 items for rice (Page 2)\n",
            "✅ Fetched 50 items for rice (Page 3)\n",
            "✅ Fetched 50 items for rice (Page 4)\n",
            "✅ Fetched 50 items for rice (Page 5)\n",
            "✅ Fetched 50 items for bread (Page 1)\n",
            "✅ Fetched 50 items for bread (Page 2)\n",
            "✅ Fetched 50 items for bread (Page 3)\n",
            "✅ Fetched 50 items for bread (Page 4)\n",
            "✅ Fetched 50 items for bread (Page 5)\n",
            "✅ Fetched 50 items for milk (Page 1)\n",
            "✅ Fetched 50 items for milk (Page 2)\n",
            "❌ Error fetching data for milk: 'value'\n",
            "✅ Fetched 50 items for egg (Page 1)\n",
            "✅ Fetched 50 items for egg (Page 2)\n",
            "✅ Fetched 50 items for egg (Page 3)\n",
            "✅ Fetched 50 items for egg (Page 4)\n",
            "✅ Fetched 50 items for egg (Page 5)\n",
            "✅ Fetched 50 items for banana (Page 1)\n",
            "✅ Fetched 50 items for banana (Page 2)\n",
            "✅ Fetched 50 items for banana (Page 3)\n",
            "✅ Fetched 50 items for banana (Page 4)\n",
            "✅ Fetched 50 items for banana (Page 5)\n",
            "✅ Fetched 50 items for apple (Page 1)\n",
            "✅ Fetched 50 items for apple (Page 2)\n",
            "✅ Fetched 50 items for apple (Page 3)\n",
            "✅ Fetched 50 items for apple (Page 4)\n",
            "✅ Fetched 50 items for apple (Page 5)\n",
            "✅ Fetched 50 items for orange (Page 1)\n",
            "✅ Fetched 50 items for orange (Page 2)\n",
            "✅ Fetched 50 items for orange (Page 3)\n",
            "✅ Fetched 50 items for orange (Page 4)\n",
            "✅ Fetched 50 items for orange (Page 5)\n",
            "✅ Fetched 50 items for cheese (Page 1)\n",
            "✅ Fetched 50 items for cheese (Page 2)\n",
            "❌ Error fetching data for cheese: 'value'\n",
            "✅ Fetched 50 items for butter (Page 1)\n",
            "✅ Fetched 50 items for butter (Page 2)\n",
            "✅ Fetched 50 items for butter (Page 3)\n",
            "✅ Fetched 50 items for butter (Page 4)\n",
            "✅ Fetched 50 items for butter (Page 5)\n",
            "❌ Error fetching data for yogurt: 'value'\n",
            "✅ Fetched 50 items for potato (Page 1)\n",
            "✅ Fetched 50 items for potato (Page 2)\n",
            "✅ Fetched 50 items for potato (Page 3)\n",
            "✅ Fetched 50 items for potato (Page 4)\n",
            "✅ Fetched 50 items for potato (Page 5)\n",
            "✅ Fetched 50 items for carrot (Page 1)\n",
            "✅ Fetched 50 items for carrot (Page 2)\n",
            "✅ Fetched 50 items for carrot (Page 3)\n",
            "✅ Fetched 50 items for carrot (Page 4)\n",
            "✅ Fetched 50 items for carrot (Page 5)\n",
            "✅ Fetched 50 items for onion (Page 1)\n",
            "✅ Fetched 50 items for onion (Page 2)\n",
            "✅ Fetched 50 items for onion (Page 3)\n",
            "✅ Fetched 50 items for onion (Page 4)\n",
            "✅ Fetched 50 items for onion (Page 5)\n",
            "❌ Error fetching data for tomato: 'value'\n",
            "✅ Fetched 50 items for chocolate (Page 1)\n",
            "✅ Fetched 50 items for chocolate (Page 2)\n",
            "✅ Fetched 50 items for chocolate (Page 3)\n",
            "✅ Fetched 50 items for chocolate (Page 4)\n",
            "✅ Fetched 50 items for chocolate (Page 5)\n",
            "✅ Fetched 50 items for coffee (Page 1)\n",
            "✅ Fetched 50 items for coffee (Page 2)\n",
            "✅ Fetched 50 items for coffee (Page 3)\n",
            "✅ Fetched 50 items for coffee (Page 4)\n",
            "✅ Fetched 50 items for coffee (Page 5)\n",
            "✅ Fetched 50 items for soda (Page 1)\n",
            "✅ Fetched 50 items for soda (Page 2)\n",
            "✅ Fetched 50 items for soda (Page 3)\n",
            "✅ Fetched 50 items for soda (Page 4)\n",
            "✅ Fetched 50 items for soda (Page 5)\n",
            "✅ Fetched 50 items for pasta (Page 1)\n",
            "✅ Fetched 50 items for pasta (Page 2)\n",
            "✅ Fetched 50 items for pasta (Page 3)\n",
            "✅ Fetched 50 items for pasta (Page 4)\n",
            "✅ Fetched 50 items for pasta (Page 5)\n",
            "✅ Fetched 50 items for beans (Page 1)\n",
            "✅ Fetched 50 items for beans (Page 2)\n",
            "✅ Fetched 50 items for beans (Page 3)\n",
            "✅ Fetched 50 items for beans (Page 4)\n",
            "✅ Fetched 50 items for beans (Page 5)\n",
            "✅ Fetched 50 items for peanuts (Page 1)\n",
            "✅ Fetched 50 items for peanuts (Page 2)\n",
            "✅ Fetched 50 items for peanuts (Page 3)\n",
            "✅ Fetched 50 items for peanuts (Page 4)\n",
            "✅ Fetched 50 items for peanuts (Page 5)\n",
            "✅ Fetched 50 items for almonds (Page 1)\n",
            "❌ Error fetching data for almonds: 'value'\n",
            "✅ Fetched 50 items for oatmeal (Page 1)\n",
            "✅ Fetched 50 items for oatmeal (Page 2)\n",
            "✅ Fetched 50 items for oatmeal (Page 3)\n",
            "✅ Fetched 50 items for oatmeal (Page 4)\n",
            "✅ Fetched 50 items for oatmeal (Page 5)\n",
            "✅ Fetched 50 items for lettuce (Page 1)\n",
            "✅ Fetched 50 items for lettuce (Page 2)\n",
            "✅ Fetched 50 items for lettuce (Page 3)\n",
            "✅ Fetched 50 items for lettuce (Page 4)\n",
            "✅ Fetched 50 items for lettuce (Page 5)\n",
            "✅ Fetched 50 items for cucumber (Page 1)\n",
            "✅ Fetched 50 items for cucumber (Page 2)\n",
            "✅ Fetched 50 items for cucumber (Page 3)\n",
            "✅ Fetched 50 items for cucumber (Page 4)\n",
            "✅ Fetched 50 items for cucumber (Page 5)\n",
            "✅ Fetched 50 items for mushroom (Page 1)\n",
            "✅ Fetched 50 items for mushroom (Page 2)\n",
            "✅ Fetched 50 items for mushroom (Page 3)\n",
            "✅ Fetched 50 items for mushroom (Page 4)\n",
            "✅ Fetched 50 items for mushroom (Page 5)\n",
            "✅ Fetched 50 items for strawberry (Page 1)\n",
            "✅ Fetched 50 items for strawberry (Page 2)\n",
            "✅ Fetched 50 items for strawberry (Page 3)\n",
            "✅ Fetched 50 items for strawberry (Page 4)\n",
            "✅ Fetched 50 items for strawberry (Page 5)\n",
            "✅ Fetched 50 items for blueberry (Page 1)\n",
            "✅ Fetched 50 items for blueberry (Page 2)\n",
            "✅ Fetched 50 items for blueberry (Page 3)\n",
            "✅ Fetched 50 items for blueberry (Page 4)\n",
            "✅ Fetched 50 items for blueberry (Page 5)\n",
            "✅ Fetched 50 items for watermelon (Page 1)\n",
            "✅ Fetched 50 items for watermelon (Page 2)\n",
            "✅ Fetched 50 items for watermelon (Page 3)\n",
            "✅ Fetched 50 items for watermelon (Page 4)\n",
            "✅ Fetched 50 items for watermelon (Page 5)\n",
            "✅ Dataset saved successfully! Total foods collected: 4996\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Your USDA API Key\n",
        "API_KEY = \"JoNfGEtoZbg4ryrpthXncEVY9DVONjHaPX6GbxUb\"\n",
        "\n",
        "# Base API URL\n",
        "BASE_URL = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
        "\n",
        "# List of food categories (expandable)\n",
        "food_queries = [\n",
        "    \"chicken\", \"beef\", \"pork\", \"fish\", \"rice\", \"bread\", \"milk\", \"egg\", \"banana\",\n",
        "    \"apple\", \"orange\", \"cheese\", \"butter\", \"yogurt\", \"potato\", \"carrot\", \"onion\",\n",
        "    \"tomato\", \"chocolate\", \"coffee\", \"soda\", \"pasta\", \"beans\", \"peanuts\", \"almonds\",\n",
        "    \"oatmeal\", \"lettuce\", \"cucumber\", \"mushroom\", \"strawberry\", \"blueberry\", \"watermelon\"\n",
        "]\n",
        "\n",
        "# List to store food data\n",
        "food_data = []\n",
        "\n",
        "# Function to fetch food data with proper pagination handling\n",
        "def fetch_food_data(query, max_pages=5):\n",
        "    page_number = 1  # Start from page 1\n",
        "\n",
        "    while page_number <= max_pages:  # Stop after max_pages\n",
        "        try:\n",
        "            # API Request\n",
        "            url = f\"{BASE_URL}?query={query}&pageNumber={page_number}&api_key={API_KEY}\"\n",
        "            response = requests.get(url)\n",
        "            data = response.json()\n",
        "\n",
        "            # Check if there are food items\n",
        "            if \"foods\" not in data or not data[\"foods\"]:\n",
        "                print(f\"✅ No more data for {query} (Page {page_number}). Stopping search.\")\n",
        "                break  # Stop fetching\n",
        "\n",
        "            # Extract relevant fields\n",
        "            for food in data[\"foods\"]:\n",
        "                nutrients = {n[\"nutrientName\"]: n[\"value\"] for n in food.get(\"foodNutrients\", [])}\n",
        "\n",
        "                # Store only useful nutrients\n",
        "                food_data.append({\n",
        "                    \"Food Name\": food.get(\"description\", \"Unknown\"),\n",
        "                    \"Calories (kcal)\": nutrients.get(\"Energy\", None),\n",
        "                    \"Protein (g)\": nutrients.get(\"Protein\", None),\n",
        "                    \"Carbs (g)\": nutrients.get(\"Carbohydrate, by difference\", None),\n",
        "                    \"Fat (g)\": nutrients.get(\"Total lipid (fat)\", None),\n",
        "                    \"FDC ID\": food.get(\"fdcId\", None)  # Unique food ID\n",
        "                })\n",
        "\n",
        "            print(f\"✅ Fetched {len(data['foods'])} items for {query} (Page {page_number})\")\n",
        "            page_number += 1  # Go to next page\n",
        "            time.sleep(1)  # Avoid rate limiting\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error fetching data for {query}: {e}\")\n",
        "            break\n",
        "\n",
        "# Fetch food data for each query\n",
        "for query in food_queries:\n",
        "    fetch_food_data(query)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(food_data)\n",
        "\n",
        "# Drop duplicate foods\n",
        "df.drop_duplicates(subset=[\"Food Name\"], keep=\"first\", inplace=True)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"usda_food_dataset.csv\", index=False)\n",
        "\n",
        "print(\"✅ Dataset saved successfully! Total foods collected:\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5rVnujO9o7h",
        "outputId": "38fa53f3-bf3f-4a55-920a-ac2e85d27f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_ID4726_UA6",
        "outputId": "1e303aa0-6eb4-4b4f-a790-b6912ab59939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QJ7BS5D_ZmE",
        "outputId": "5c62938c-148c-4318-ce04-e7d6998db3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ FAISS index rebuilt with improved embeddings!\n"
          ]
        }
      ],
      "source": [
        "# import faiss\n",
        "# import pandas as pd\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# import numpy as np\n",
        "\n",
        "# # Load dataset\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/usda_food_dataset.csv\")\n",
        "\n",
        "# # Load sentence transformer model\n",
        "# model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# # Generate food embeddings\n",
        "# food_names = df[\"Food Name\"].tolist()\n",
        "# embeddings = model.encode(food_names, convert_to_numpy=True)\n",
        "\n",
        "# # Normalize embeddings for cosine similarity\n",
        "# embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "# # Create FAISS index with Inner Product (Cosine Similarity)\n",
        "# dimension = embeddings.shape[1]\n",
        "# index = faiss.IndexFlatIP(dimension)  # IP (Inner Product) works for cosine similarity\n",
        "\n",
        "# # Add embeddings to FAISS index\n",
        "# index.add(embeddings)\n",
        "\n",
        "# # Save FAISS index to Google Drive\n",
        "# faiss.write_index(index, \"/content/drive/MyDrive/faiss_food_index\")\n",
        "\n",
        "# print(\"✅ FAISS index rebuilt with corrected embeddings!\")\n",
        "\n",
        "import faiss\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/usda_food_dataset.csv\")\n",
        "\n",
        "# Load improved sentence transformer model\n",
        "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "# Generate food embeddings\n",
        "food_names = df[\"Food Name\"].tolist()\n",
        "embeddings = model.encode(food_names, convert_to_numpy=True)\n",
        "\n",
        "# Normalize embeddings for cosine similarity\n",
        "embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "# Create FAISS index with Inner Product (Cosine Similarity)\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "index.add(embeddings)\n",
        "\n",
        "# Save FAISS index to Google Drive\n",
        "faiss.write_index(index, \"/content/drive/MyDrive/faiss_food_index\")\n",
        "\n",
        "print(\"✅ FAISS index rebuilt with improved embeddings!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV-m3aAWcP-b",
        "outputId": "4a730998-345d-4961-8f5e-b12a718e326c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ov94L4HJ_zPw"
      },
      "outputs": [],
      "source": [
        "# def search_food(query, top_k=5):\n",
        "#     # Convert query to vector embedding\n",
        "#     query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "#     query_embedding = query_embedding / np.linalg.norm(query_embedding)  # Normalize\n",
        "\n",
        "#     # Search FAISS index\n",
        "#     distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "#     # Retrieve top food names and nutrition info\n",
        "#     results = []\n",
        "#     for i in range(top_k):\n",
        "#         idx = indices[0][i]\n",
        "#         if idx >= 0:  # Valid result\n",
        "#             food_name = df.iloc[idx][\"Food Name\"]\n",
        "#             calories = df.iloc[idx][\"Calories (kcal)\"]\n",
        "#             protein = df.iloc[idx][\"Protein (g)\"]\n",
        "#             fat = df.iloc[idx][\"Fat (g)\"]\n",
        "#             carbs = df.iloc[idx][\"Carbs (g)\"]\n",
        "#             results.append({\n",
        "#                 \"Food\": food_name,\n",
        "#                 \"Calories\": calories,\n",
        "#                 \"Protein\": protein,\n",
        "#                 \"Fat\": fat,\n",
        "#                 \"Carbs\": carbs\n",
        "#             })\n",
        "\n",
        "#     return results\n",
        "\n",
        "def search_food(query, top_k=5, dietary_preference=None):\n",
        "    # Convert query to vector embedding\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "\n",
        "    # Ensure the embedding has the correct shape\n",
        "    query_embedding = np.asarray(query_embedding, dtype=np.float32).reshape(1, -1)\n",
        "\n",
        "    # Normalize the query embedding (same as stored embeddings)\n",
        "    query_embedding /= np.linalg.norm(query_embedding)\n",
        "\n",
        "    # Verify that dimensions match before searching\n",
        "    assert query_embedding.shape[1] == index.d, f\"Dimension mismatch: Query {query_embedding.shape[1]}, Index {index.d}\"\n",
        "\n",
        "    # Search FAISS index\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # Retrieve top food names and nutrition info\n",
        "    results = []\n",
        "    for i in range(top_k):\n",
        "        idx = indices[0][i]\n",
        "        if idx >= 0:\n",
        "            food_name = df.iloc[idx][\"Food Name\"]\n",
        "            calories = df.iloc[idx][\"Calories (kcal)\"]\n",
        "            protein = df.iloc[idx][\"Protein (g)\"]\n",
        "            fat = df.iloc[idx][\"Fat (g)\"]\n",
        "            carbs = df.iloc[idx][\"Carbs (g)\"]\n",
        "\n",
        "            # Apply dietary preference filtering\n",
        "            if dietary_preference == \"low_calorie\" and calories > 200:\n",
        "                continue\n",
        "            if dietary_preference == \"high_protein\" and protein < 10:\n",
        "                continue\n",
        "\n",
        "            results.append({\n",
        "                \"Food\": food_name,\n",
        "                \"Calories\": calories,\n",
        "                \"Protein\": protein,\n",
        "                \"Fat\": fat,\n",
        "                \"Carbs\": carbs\n",
        "            })\n",
        "\n",
        "    return results if results else \"No suitable options found. Try adjusting dietary preferences.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5_VPZ-8_3Bo",
        "outputId": "6d01c00f-1ed2-4853-c68f-722fbf9bbe3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Closest Matches for: grilled chicken\n",
            "Barbecue chicken - 167.0 kcal, Protein: 19.0g, Fat: 4.64g, Carbs: 12.23g\n",
            "Chicken wing, grilled with sauce - 250.0 kcal, Protein: 19.03g, Fat: 15.49g, Carbs: 7.28g\n",
            "Chicken fillet, grilled - 151.0 kcal, Protein: 22.31g, Fat: 5.81g, Carbs: 2.36g\n",
            "Chicken, chicken roll, roasted - 164.0 kcal, Protein: 26.68g, Fat: 6.33g, Carbs: 0.0g\n",
            "Chicken with gravy - 129.0 kcal, Protein: 18.88g, Fat: 5.21g, Carbs: 1.58g\n"
          ]
        }
      ],
      "source": [
        "query = \"grilled chicken\"\n",
        "results = search_food(query)\n",
        "\n",
        "print(\"🔍 Closest Matches for:\", query)\n",
        "for r in results:\n",
        "    print(f\"{r['Food']} - {r['Calories']} kcal, Protein: {r['Protein']}g, Fat: {r['Fat']}g, Carbs: {r['Carbs']}g\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9jvHGRncABjM"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Load the FAISS index\n",
        "faiss_index_path = \"/content/drive/MyDrive/faiss_food_index\"\n",
        "index = faiss.read_index(faiss_index_path)\n",
        "\n",
        "# Load the food dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/usda_food_dataset.csv\")\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ7Cc62-AfBa",
        "outputId": "1712b6d5-506d-43b7-ab4d-edf3ad9ebebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.20.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smbi5C2HAhkW"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "\n",
        "# Initialize the Groq client\n",
        "groq_client = Groq(api_key=\"API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Mq9__tGaJFUc"
      },
      "outputs": [],
      "source": [
        "# def detect_query_intent(query):\n",
        "#     # Keywords for low-calorie queries\n",
        "#     low_calorie_keywords = [\"low-calorie\", \"low calorie\", \"healthy\", \"light\", \"diet\"]\n",
        "\n",
        "#     # Keywords for high-calorie queries\n",
        "#     high_calorie_keywords = [\"high-calorie\", \"high calorie\", \"most calories\", \"energy-dense\", \"calorie-dense\"]\n",
        "\n",
        "#     # Check for low-calorie intent\n",
        "#     if any(keyword in query.lower() for keyword in low_calorie_keywords):\n",
        "#         return \"low_calorie\"\n",
        "\n",
        "#     # Check for high-calorie intent\n",
        "#     elif any(keyword in query.lower() for keyword in high_calorie_keywords):\n",
        "#         return \"high_calorie\"\n",
        "\n",
        "#     # Default to low-calorie if intent is unclear\n",
        "#     else:\n",
        "#         return \"low_calorie\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JMNdtd0ZAwn1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def retrieve_food_items(query, top_k=5):\n",
        "    # Convert query to vector embedding\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    query_embedding = query_embedding / np.linalg.norm(query_embedding)  # Normalize\n",
        "\n",
        "    # Search FAISS index\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # Retrieve top food items\n",
        "    results = []\n",
        "    for i in range(top_k):\n",
        "        if indices[0][i] != -1:  # Ensure valid result\n",
        "            food_name = df.iloc[indices[0][i]][\"Food Name\"]\n",
        "            calories = df.iloc[indices[0][i]][\"Calories (kcal)\"]\n",
        "            protein = df.iloc[indices[0][i]][\"Protein (g)\"]\n",
        "            carbs = df.iloc[indices[0][i]][\"Carbs (g)\"]\n",
        "            fat = df.iloc[indices[0][i]][\"Fat (g)\"]\n",
        "\n",
        "            results.append({\n",
        "                \"Food\": food_name,\n",
        "                \"Calories\": calories,\n",
        "                \"Protein\": protein,\n",
        "                \"Carbs\": carbs,\n",
        "                \"Fat\": fat\n",
        "            })\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HLHIShs6A082"
      },
      "outputs": [],
      "source": [
        "def generate_response(query, retrieved_items):\n",
        "    # Prepare the context for the Groq API\n",
        "    context = \"Here are some relevant food items based on your query:\\n\"\n",
        "    for item in retrieved_items:\n",
        "        context += f\"- {item['Food']}: {item['Calories']} kcal, {item['Protein']}g protein, {item['Carbs']}g carbs, {item['Fat']}g fat\\n\"\n",
        "\n",
        "    # Generate a response using the Groq API\n",
        "    response = groq_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a specialized assistant that provides nutritional insights based on the provided food data. Use only the given context to answer user queries. Do not generate information beyond the provided dataset. Focus on evaluating the nutritional content of the retrieved food items, explaining their health benefits or concerns, comparing their macronutrient values.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"{query}\\n\\n{context}\"\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",  # Use the appropriate Groq model\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6Osex5nEA4hL"
      },
      "outputs": [],
      "source": [
        "def rag_agent(query, top_k=5):\n",
        "    # Retrieve relevant food items\n",
        "    retrieved_items = retrieve_food_items(query, top_k)\n",
        "\n",
        "    # Generate a response using the Groq API\n",
        "    response = generate_response(query, retrieved_items)\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udYxFPwjA8Ne",
        "outputId": "c8c84c28-0ada-4195-e839-7582d157089a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What are some healthy low-calorie food options?\n",
            "Response: Based on the provided food items, here are some relatively healthy low-calorie food options:\n",
            "\n",
            "1. Milk, chocolate, lowfat, reduced sugar: With 237.0 kcal, this option is relatively low in calories and also provides 3.43g of protein. The carb content is moderate, and the fat content is low.\n",
            "\n",
            "2. Bread, reduced-calorie, oatmeal: This option has 210.0 kcal, which is relatively low in calories, and also provides 7.6g of protein. The carb content is moderate, but it is a good source of fiber due to the oatmeal content.\n",
            "\n",
            "In comparison, the other options are higher in calories:\n",
            "- Cookies, oatmeal, reduced fat: 1530.0 kcal (very high)\n",
            "- Snacks, potato chips, reduced fat: 471.0 kcal (moderately high)\n",
            "- Cookie, oatmeal, reduced fat, NS as to raisins: 365.0 kcal (moderately high)\n",
            "\n",
            "Between the two relatively low-calorie options, the milk has a better macronutrient balance with lower carbs and fat, while the reduced-calorie oatmeal bread has higher protein content. Choosing the milk would be a better option for those watching their carb intake, while the oatmeal bread would be more suitable for those seeking a higher protein content.\n"
          ]
        }
      ],
      "source": [
        "# Test the RAG agent with a query\n",
        "query = \"What are some healthy low-calorie food options?\"\n",
        "response = rag_agent(query)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Response:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGokMUHsA-S7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
